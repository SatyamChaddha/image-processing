% vim:ft=tex
% rubber: module xelatex
\subsection{Face features extraction}

The first scale-invariant feature extraction algorithm was SIFT, described in \cite{SIFT}. SIFT is designed to be able to reliably detect features in altered (e.g. contrast-shifted, re-oriented or scaled) images. SIFT uses a database of training images with identified features to attempt to classify objects in new images based on their feature vectors. Image features are assumed to be the maxima and minima of the difference of Gaussians applied to the images. Outliers are discovered and removed by comparing each image feature with the model, verified by least squares.

The SURF extractor, described in \cite{SURF}, is an attempt to improve upon SIFT by speeding up computation without loss of computation quality or robustness. SURF achieves this improvement by convolving images with integral images, using a Hessian matrix-based detector, using a distribution-based descriptor, and simplifying to only 64 dimensions (see \cite{SURF}). An open-source implementation of this algorithm is OpenSURF, described in \cite{OpenSURF}. OpenCV also includes an implementation of the SURF algorithm. We use both these forms in our program, and add our own implementation of SURF. Our implementation is inspired by (and therefore structured similarly to) the OpenSURF implementation.

Our implementation uses the response layers and filter sizes from \cite{SURF}. This limits the range of possible values for the 'octaves' and 'interval' parameters to (1-5) and (3-4) respectively. The OpenSURF implementation simply ignores the 'intervals' parameter in its calculations.

When estimating the determinant of the Hessian matrix (from the filter response values), a weight of $0.9$ for the $D_{xy}$ direction is used. This comes from the article.

\begin{itemize}
\item The three implementations (ours, OpenCV and OpenSURF) use
  somewhat different threshold values. OpenCV does not area normalise
  the values (I think; the code is quite convoluted), which might be a
  good bet for why those are different. OpenSURF represents grey scale
  values as floating point values between 0 and 1, whereas we
  represent them as 0-255 int values, which should account for the
  discrepancies between values here.
\item The interpolation between points to get subpixel accuracy for
  interest points follows the method in \cite{inv-features}, which
  amounts to solving a linear system using pixel differences as
  approximations for derivatives. In \cite{SURF}, it is implied that
  this should be used to iteratively interpolate keypoint locations,
  and discard those that do not converge. However, both OpenCV and
  OpenSURF appear to just use the interpolation deltas to discard
  keypoints that interpolate to a different point, and no
  interpolation is done. We do the same; though for some reason, the
  interpolation seems to make the results worse (i.e. fit worse with
  the other implementations).
\end{itemize}
